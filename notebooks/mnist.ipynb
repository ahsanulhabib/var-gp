{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from collections import defaultdict\n",
    "# \n",
    "## Parse the VCL experiments folder.\n",
    "# def parse_raw_vcl(path):\n",
    "#     results = defaultdict(dict)\n",
    "\n",
    "#     for exp in os.listdir(path):\n",
    "#         if not exp.startswith('nn_model'):\n",
    "#             continue\n",
    "\n",
    "#         kv = exp.split('_')\n",
    "#         layers = '_'.join([v.strip() for v in kv[kv.index('hidden') + 2].lstrip('[').rstrip(']').split(',')])\n",
    "#         coreset = kv[kv.index('coreset') + 2]\n",
    "#         seed = kv[kv.index('seed') + 1]\n",
    "\n",
    "#         results[f'vcl_{layers}_coreset_{coreset}'][seed] = np.load(f'{path}/{exp}/test_acc.npz')['acc']\n",
    "\n",
    "#     for seed in range(5):\n",
    "#         avg_acc = []\n",
    "#         acc_mat = results['vcl_100_100_coreset_100'][f'{seed + 1}']\n",
    "#         for i, row in enumerate(acc_mat):\n",
    "#             avg_acc.append(np.mean(row[:i + 1]))\n",
    "\n",
    "#         print('\\n'.join([str(v) for v in avg_acc]))\n",
    "#         # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = {\n",
    "    'vcl_100': 'VCL, [100]',\n",
    "    'vcl_100_coreset_50': 'VCL + coreset (50), [100]',\n",
    "    'vcl_100_coreset_100': 'VCL + coreset (100), [100]',\n",
    "    'vcl_100_100': 'VCL, [100, 100]',\n",
    "    'vcl_100_100_coreset_50': 'VCL + coreset (50), [100, 100]',\n",
    "    'vcl_100_100_coreset_100': 'VCL + coreset (100), [100, 100]',\n",
    "    'var_gp': 'VAR-GP',\n",
    "    'var_gp_block_diag': 'VAR-GP (Block Diagonal)',\n",
    "    'var_gp_mle_hypers': 'VAR-GP (MLE Hyperparameters)',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('split_mnist_results.csv')\n",
    "data.rename(columns=cmap, inplace=True)\n",
    "\n",
    "melt_data = data.melt(id_vars=['task'], value_vars=[cmap[k] for k in ['var_gp', 'vcl_100_coreset_100', 'vcl_100_100_coreset_100']], var_name='Approach', value_name='vals')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "g = sns.lineplot(x='task', y='vals', hue='Approach', marker='o', data=melt_data, ci='sd')\n",
    "g.set(xlabel='Task', ylabel='Test Accuracy', ylim=(0.6,1.005));\n",
    "g.legend(loc='lower left', fontsize=20)\n",
    "g.set_yticks(np.arange(0.6, 1.0 + 1e-3, 0.05))\n",
    "g.set_xticks(range(5))\n",
    "if save:\n",
    "    g.figure.savefig('split_mnist.png', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_data = data.melt(id_vars=['task'], value_vars=[cmap[k] for k in ['var_gp', 'var_gp_block_diag', 'var_gp_mle_hypers']], var_name='Approach', value_name='vals')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "g = sns.lineplot(x='task', y='vals', hue='Approach', marker='o', data=melt_data, ci='sd')\n",
    "g.set(xlabel='Task', ylabel='Test Accuracy', ylim=(0.0,1.005));\n",
    "g.legend(loc='bottom left', fontsize=20)\n",
    "g.set_yticks(np.arange(0.6, 1.0 + 1e-3, 0.05))\n",
    "g.set_xticks(range(5))\n",
    "if save:\n",
    "    g.figure.savefig('split_mnist_ep_mean_mle_hypers.png', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Inducing Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_inducing_pts(ckpt_dir):\n",
    "    for ckpt in range(5):\n",
    "        state_dict = torch.load(f'{ckpt_dir}/ckpt{ckpt}.pt', map_location=torch.device('cpu'))\n",
    "        z = state_dict.get('z')\n",
    "        N = 4\n",
    "        ind_pts_subset = z[2*ckpt:2*ckpt+2][:, torch.randperm(z.size(1))[:N], :].view(-1, N, 28, 28)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, N, sharey=True, sharex=True, figsize=(20,10))\n",
    "        fig.subplots_adjust(hspace=0.05, wspace=0.001)\n",
    "        for i in range(2):\n",
    "            for j in range(N):\n",
    "                axes[i, j].imshow(ind_pts_subset[i, j], interpolation='bilinear', cmap='gray')\n",
    "                axes[i, j].set(aspect='equal')\n",
    "                axes[i, j].grid(False)\n",
    "                axes[i, j].axis('off')\n",
    "                axes[i, j].margins(x=0.0, y=0.0)\n",
    "\n",
    "        fig.suptitle(f'After Task {ckpt}', fontsize=50)\n",
    "        # fig.tight_layout()\n",
    "\n",
    "        if save:\n",
    "            fig.savefig(f'smnist_viz_{ckpt + 1}.png', bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "# Add path to checkpoint directory.\n",
    "ckpt_dir = '/Users/sanyam/Downloads/ckpt'\n",
    "plot_inducing_pts(ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permuted MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('permuted_mnist_results.csv')\n",
    "data.rename(columns=cmap, inplace=True)\n",
    "\n",
    "melt_data = data.melt(id_vars=['task'], value_vars=[cmap[k] for k in ['var_gp', 'vcl_100_coreset_100', 'vcl_100_100_coreset_100']], var_name='Approach', value_name='vals')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "g = sns.lineplot(x='task', y='vals', hue='Approach', marker='o', data=melt_data, ci='sd')\n",
    "g.set(xlabel='Task', ylabel='Test Accuracy', ylim=(0.6,1.0));\n",
    "g.legend(loc='lower left', fontsize=20)\n",
    "g.set_yticks(np.arange(0.6, 1.0 + 1e-3, 0.05))\n",
    "g.set_xticks(range(10))\n",
    "if save:\n",
    "    g.figure.savefig('permuted_mnist.png', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_data = data.melt(id_vars=['task'], value_vars=[cmap[k] for k in ['var_gp', 'var_gp_block_diag', 'var_gp_mle_hypers']], var_name='Approach', value_name='vals')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "g = sns.lineplot(x='task', y='vals', hue='Approach', marker='o', data=melt_data, ci=99)\n",
    "g.set(xlabel='Task', ylabel='Test Accuracy', ylim=(0.0,1.0));\n",
    "g.legend(loc='center right', fontsize=20)\n",
    "g.set_yticks(np.arange(0.0, 1.0 + 1e-3, 0.05))\n",
    "g.set_xticks(range(10))\n",
    "if save:\n",
    "    g.figure.savefig('permuted_mnist_ep_mean_mle_hypers.png', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('cgp': conda)",
   "language": "python",
   "name": "python37664bitcgpcondacf7e78d380a64f8f9d09797562a4bc19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sns.set()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "if os.path.abspath('..') not in sys.path:\n",
    "    sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import os\n",
    "# from collections import defaultdict\n",
    "# \n",
    "## Parse the VCL experiments folder.\n",
    "# def parse_raw_vcl(path):\n",
    "#     results = defaultdict(dict)\n",
    "\n",
    "#     for exp in os.listdir(path):\n",
    "#         if not exp.startswith('nn_model'):\n",
    "#             continue\n",
    "\n",
    "#         kv = exp.split('_')\n",
    "#         layers = '_'.join([v.strip() for v in kv[kv.index('hidden') + 2].lstrip('[').rstrip(']').split(',')])\n",
    "#         coreset = kv[kv.index('coreset') + 2]\n",
    "#         seed = kv[kv.index('seed') + 1]\n",
    "\n",
    "#         results[f'vcl_{layers}_coreset_{coreset}'][seed] = np.load(f'{path}/{exp}/test_acc.npz')['acc']\n",
    "\n",
    "#     for seed in range(5):\n",
    "#         avg_acc = []\n",
    "#         acc_mat = results['vcl_100_100_coreset_100'][f'{seed + 1}']\n",
    "#         for i, row in enumerate(acc_mat):\n",
    "#             avg_acc.append(np.mean(row[:i + 1]))\n",
    "\n",
    "#         print('\\n'.join([str(v) for v in avg_acc]))\n",
    "#         # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = {\n",
    "    'vcl_100': 'VCL, [100]',\n",
    "    'vcl_100_coreset_50': 'VCL + coreset (50), [100]',\n",
    "    'vcl_100_coreset_100': 'VCL + coreset (100), [100]',\n",
    "    'vcl_100_100': 'VCL, [100, 100]',\n",
    "    'vcl_100_100_coreset_50': 'VCL + coreset (50), [100, 100]',\n",
    "    'vcl_100_100_coreset_100': 'VCL + coreset (100), [100, 100]',\n",
    "    'var_gp': 'VAR-GP',\n",
    "    'var_gp_block_diag': 'VAR-GP (Block Diagonal)',\n",
    "    'var_gp_mle_hypers': 'VAR-GP (MLE Hyperparameters)',\n",
    "    'var_gp_global': 'VAR-GP (Global)',\n",
    "}\n",
    "\n",
    "def plot_test_acc(data, clist, min_y=0.0, max_x=1, save=False, name=None, loc='best'):\n",
    "    data.rename(columns=cmap, inplace=True)\n",
    "    \n",
    "    melt_data = data.melt(id_vars=['task'], value_vars=[cmap[k] for k in clist], var_name='Method', value_name='vals')\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    g = sns.lineplot(x='task', y='vals', hue='Method', marker='o', data=melt_data, ci=99)\n",
    "    g.set(xlabel='Task', ylabel='Test Accuracy', ylim=(min_y,1.005));\n",
    "    g.legend(loc=loc, fontsize=20)\n",
    "    g.set_xlabel(xlabel='Task', fontsize=20)\n",
    "    g.set_ylabel(ylabel='Test Accuracy', fontsize=20)\n",
    "    g.set_yticks(np.arange(min_y, 1.0 + 1e-3, 0.05))\n",
    "    g.set_xticks(range(max_x))\n",
    "    \n",
    "    if save and name is not None:\n",
    "        g.figure.savefig(name, bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split MNIST Test Accuracy Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('results/smnist.csv')\n",
    "\n",
    "plot_test_acc(data, ['var_gp', 'vcl_100_coreset_100', 'vcl_100_100_coreset_100'],\n",
    "              min_y=0.7, save=False, name='split_mnist.png', max_x=5)\n",
    "\n",
    "plot_test_acc(data, ['var_gp', 'var_gp_block_diag', 'var_gp_global', 'var_gp_mle_hypers'],\n",
    "              save=False, name='split_mnist_ep_mean_mle_hypers.png', max_x=5, loc='lower left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Inducing Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_inducing_pts(ckpt_dir, save=False):\n",
    "    for ckpt in range(5):\n",
    "        state_dict = torch.load(f'{ckpt_dir}/ckpt{ckpt}.pt', map_location=torch.device('cpu'))\n",
    "        z = state_dict.get('z')\n",
    "        N = 4\n",
    "        ind_pts_subset = z[2*ckpt:2*ckpt+2][:, torch.randperm(z.size(1))[:N], :].view(-1, N, 28, 28)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, N, sharey=True, sharex=True, figsize=(20,10))\n",
    "        fig.subplots_adjust(hspace=0.05, wspace=0.001)\n",
    "        for i in range(2):\n",
    "            for j in range(N):\n",
    "                axes[i, j].imshow(ind_pts_subset[i, j], interpolation='bilinear', cmap='gray')\n",
    "                axes[i, j].set(aspect='equal')\n",
    "                axes[i, j].grid(False)\n",
    "                axes[i, j].axis('off')\n",
    "                axes[i, j].margins(x=0.0, y=0.0)\n",
    "\n",
    "        fig.suptitle(f'After Task {ckpt}', fontsize=50)\n",
    "        # fig.tight_layout()\n",
    "\n",
    "        if save:\n",
    "            fig.savefig(f'smnist_viz_{ckpt + 1}.png', bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "# Add path to checkpoint directory.\n",
    "ckpt_dir = 'results/vargp-smnist'\n",
    "plot_inducing_pts(ckpt_dir, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Predictive Entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.distributions import Categorical\n",
    "from continual_gp.train_utils import create_class_vargp\n",
    "from continual_gp.datasets import SplitMNIST\n",
    "\n",
    "run_dir = 'results/vargp-smnist'\n",
    "ds = SplitMNIST('/tmp', train=False)\n",
    "\n",
    "ent_mat = []\n",
    "\n",
    "prev_params = []\n",
    "for t in tqdm(range(5)):\n",
    "    mean_ent_list = []\n",
    "    with torch.no_grad():\n",
    "        cur_params = torch.load(f'{run_dir}/ckpt{t}.pt', map_location=device)\n",
    "        gp = create_class_vargp(ds, M=60, n_f=50, n_var_samples=20, prev_params=prev_params).to(device)\n",
    "        gp.load_state_dict(cur_params)\n",
    "\n",
    "        for task in tqdm(range(5), leave=False):\n",
    "            ds.filter_by_class([2 * task, 2 * task + 1])\n",
    "  \n",
    "            all_entropy = 0.0\n",
    "            \n",
    "            for x, _ in tqdm(DataLoader(ds, batch_size=256), leave=False):\n",
    "                dist = Categorical(probs=gp.predict(x.to(device)))\n",
    "                all_entropy += dist.entropy().sum()\n",
    "            \n",
    "            mean_ent_list.append(all_entropy.cpu().item() / len(ds))\n",
    "\n",
    "    ds.filter_by_class()\n",
    "    prev_params.append(cur_params)\n",
    "    ent_mat.append(mean_ent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "im = plt.imshow(torch.Tensor(ent_mat) / torch.tensor(10.0).log(), cmap='gray')\n",
    "plt.xlabel('Test Tasks', fontsize=20)\n",
    "plt.ylabel('Train Tasks', fontsize=20)\n",
    "plt.grid(False);\n",
    "# plt.colorbar(im)\n",
    "# plt.savefig(f'smnist_norm_entropy.png', bbox_inches='tight', pad_inches=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permuted MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('results/pmnist.csv')\n",
    "\n",
    "plot_test_acc(data, ['var_gp', 'vcl_100_coreset_100', 'vcl_100_100_coreset_100'],\n",
    "              min_y=0.7, save=False, name='permuted_mnist.png', max_x=10)\n",
    "\n",
    "plot_test_acc(data, ['var_gp', 'var_gp_block_diag', 'var_gp_global', 'var_gp_mle_hypers'],\n",
    "              save=False, name='permuted_mnist_ep_mean_mle_hypers.png', max_x=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Predictive Entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.distributions import Categorical\n",
    "from continual_gp.train_utils import create_class_vargp, set_seeds\n",
    "from continual_gp.datasets import PermutedMNIST\n",
    "\n",
    "set_seeds(1)\n",
    "tasks = [torch.arange(784)] + PermutedMNIST.create_tasks(n=9)\n",
    "\n",
    "run_dir = 'results/vargp-pmnist-seed1'\n",
    "ds = PermutedMNIST('/tmp', train=False)\n",
    "\n",
    "ent_mat = []\n",
    "\n",
    "prev_params = []\n",
    "for t in tqdm(range(10)):\n",
    "    mean_ent_list = []\n",
    "    with torch.no_grad():\n",
    "        cur_params = torch.load(f'{run_dir}/ckpt{t}.pt', map_location=device)\n",
    "        gp = create_class_vargp(ds, M=100, n_f=50, n_var_samples=20, prev_params=prev_params).to(device)\n",
    "        gp.load_state_dict(cur_params)\n",
    "\n",
    "        for i, task in tqdm(enumerate(tasks), leave=False):\n",
    "            ds = PermutedMNIST('/tmp', train=False)\n",
    "            ds.set_task(task)\n",
    "  \n",
    "            all_entropy = 0.0\n",
    "            \n",
    "            for x, _ in tqdm(DataLoader(ds, batch_size=256), leave=False):\n",
    "                dist = Categorical(probs=gp.predict(x.to(device)))\n",
    "                all_entropy += dist.entropy().sum()\n",
    "            \n",
    "            mean_ent_list.append(all_entropy.cpu().item() / len(ds))\n",
    "\n",
    "    prev_params.append(cur_params)\n",
    "    ent_mat.append(mean_ent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "im = plt.imshow(torch.Tensor(ent_mat) / torch.tensor(10.0).log(), cmap='gray')\n",
    "plt.xlabel('Test Tasks', fontsize=20)\n",
    "plt.ylabel('Train Tasks', fontsize=20)\n",
    "plt.grid(False);\n",
    "# plt.colorbar(im)\n",
    "# plt.savefig(f'pmnist_norm_entropy.png', bbox_inches='tight', pad_inches=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VCL Predictive Entropy\n",
    "\n",
    "### Split MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_mat = np.load('results/vcl-smnist-seed1/test_acc_and_ent.npz')['ent']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "im = plt.imshow(ent_mat, cmap='gray')\n",
    "plt.xlabel('Test Tasks', fontsize=20)\n",
    "plt.ylabel('Train Tasks', fontsize=20)\n",
    "plt.grid(False);\n",
    "# plt.colorbar(im)\n",
    "# plt.savefig(f'vcl_smnist_norm_entropy.png', bbox_inches='tight', pad_inches=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permuted MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_mat = np.load('results/vcl-pmnist-seed1/test_acc_and_ent.npz')['ent']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "im = plt.imshow(ent_mat, cmap='gray')\n",
    "plt.xlabel('Test Tasks', fontsize=20)\n",
    "plt.ylabel('Train Tasks', fontsize=20)\n",
    "plt.grid(False);\n",
    "# plt.colorbar(im)\n",
    "# plt.savefig(f'vcl_pmnist_norm_entropy.png', bbox_inches='tight', pad_inches=0);"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
